{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from router_poc import settings as S\n",
    "from router_poc import router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_parquet(S.DATA_DIR / \"intermediate\" / \"stanford_mmlu_results.embeddings.parquet\")\n",
    "labels = pd.read_parquet(S.DATA_DIR / \"intermediate\" / \"stanford_mmlu_results.parquet\")\n",
    "\n",
    "data = pd.merge(embeddings, labels, on=\"prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should have been done in data gen, now we hope we are getting the same splits\n",
    "prompts = data[\"prompt\"].unique()\n",
    "\n",
    "train, val = train_test_split(prompts, test_size=0.2, random_state=42)\n",
    "train = data.query(\"prompt in @train\")\n",
    "val = data.query(\"prompt in @val\")\n",
    "\n",
    "# Seems like I didn't exclude all of prompts using mistral small.\n",
    "# It seems to have used slightly different prompt, so it's hard\n",
    "# to compare the results. Let's just ignore it\n",
    "train = train.query(\"model != 'mistralai/mistral-small-2402'\").copy()\n",
    "val = val.query(\"model != 'mistralai/mistral-small-2402'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best LLM: anthropic/claude-3-5-sonnet-20241022 (87.61%)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Worst LLM: anthropic/claude-3-5-haiku-20241022 (73.80%)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_llm = train.groupby(\"model\")[\"exact_match\"].mean()\n",
    "best_llm_accuracy = best_llm.max()\n",
    "best_llm_name = best_llm.idxmax()\n",
    "\n",
    "worst_llm_accuracy = best_llm.min()\n",
    "worst_llm_name = best_llm.idxmin()\n",
    "\n",
    "display(\n",
    "    f\"Best LLM: {best_llm_name} ({best_llm_accuracy:.2%})\",\n",
    "    f\"Worst LLM: {worst_llm_name} ({worst_llm_accuracy:.2%})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoutedPrompt(prompt='What is the capital of France?', llm_name='google/gemini-2.0-flash-exp', response='The capital of France is **Paris**.\\n')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(router)\n",
    "\n",
    "random_router = router.Router(train[\"model\"].unique(), \"random\")\n",
    "random_router(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoutedPrompt(prompt='What is the capital of France?', llm_name='openai/gpt-4-turbo-2024-04-09', response='The capital of France is Paris.')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(router)\n",
    "strength_router = router.Router(train[\"model\"].unique(), \"absolute\")\n",
    "strength_router(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can cheat and to evaluate routing models on val set we don't actually have to call the lms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_router(router: router.Router, val_set: pd.DataFrame):\n",
    "    results = []\n",
    "    prompts = val_set[\"prompt\"].unique()\n",
    "    for prompt in prompts:\n",
    "        chosen_llm = router.router(prompt)\n",
    "        exact_match = val_set.query(\"model == @chosen_llm & prompt == @prompt\")[\"exact_match\"].values[0]\n",
    "        results.append({\n",
    "            \"prompt\": prompt,\n",
    "            \"chosen_llm\": chosen_llm,\n",
    "            \"exact_match\": exact_match,\n",
    "        })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>chosen_llm</th>\n",
       "      <th>exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Answer with only a single letter.\\n\\nThe follo...</td>\n",
       "      <td>anthropic/claude-3-5-sonnet-20241022</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Answer with only a single letter.\\n\\nThe follo...</td>\n",
       "      <td>mistralai/mistral-large-2407</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Answer with only a single letter.\\n\\nThe follo...</td>\n",
       "      <td>mistralai/mistral-large-2407</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Answer with only a single letter.\\n\\nThe follo...</td>\n",
       "      <td>openai/gpt-4-turbo-2024-04-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Answer with only a single letter.\\n\\nThe follo...</td>\n",
       "      <td>openai/gpt-4-turbo-2024-04-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>Answer with only a single letter.\\n\\nThe follo...</td>\n",
       "      <td>anthropic/claude-3-5-sonnet-20241022</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>Answer with only a single letter.\\n\\nThe follo...</td>\n",
       "      <td>google/gemini-2.0-flash-exp</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>Answer with only a single letter.\\n\\nThe follo...</td>\n",
       "      <td>anthropic/claude-3-5-sonnet-20241022</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>Answer with only a single letter.\\n\\nThe follo...</td>\n",
       "      <td>anthropic/claude-3-5-sonnet-20241022</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>Answer with only a single letter.\\n\\nThe follo...</td>\n",
       "      <td>mistralai/mistral-large-2407</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2853 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  \\\n",
       "0     Answer with only a single letter.\\n\\nThe follo...   \n",
       "1     Answer with only a single letter.\\n\\nThe follo...   \n",
       "2     Answer with only a single letter.\\n\\nThe follo...   \n",
       "3     Answer with only a single letter.\\n\\nThe follo...   \n",
       "4     Answer with only a single letter.\\n\\nThe follo...   \n",
       "...                                                 ...   \n",
       "2848  Answer with only a single letter.\\n\\nThe follo...   \n",
       "2849  Answer with only a single letter.\\n\\nThe follo...   \n",
       "2850  Answer with only a single letter.\\n\\nThe follo...   \n",
       "2851  Answer with only a single letter.\\n\\nThe follo...   \n",
       "2852  Answer with only a single letter.\\n\\nThe follo...   \n",
       "\n",
       "                                chosen_llm  exact_match  \n",
       "0     anthropic/claude-3-5-sonnet-20241022          1.0  \n",
       "1             mistralai/mistral-large-2407          1.0  \n",
       "2             mistralai/mistral-large-2407          1.0  \n",
       "3            openai/gpt-4-turbo-2024-04-09          1.0  \n",
       "4            openai/gpt-4-turbo-2024-04-09          1.0  \n",
       "...                                    ...          ...  \n",
       "2848  anthropic/claude-3-5-sonnet-20241022          1.0  \n",
       "2849           google/gemini-2.0-flash-exp          1.0  \n",
       "2850  anthropic/claude-3-5-sonnet-20241022          1.0  \n",
       "2851  anthropic/claude-3-5-sonnet-20241022          1.0  \n",
       "2852          mistralai/mistral-large-2407          1.0  \n",
       "\n",
       "[2853 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strength_router_results = evaluate_router(strength_router, val)\n",
    "strength_router_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9263932702418507)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strength_router_results[\"exact_match\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
